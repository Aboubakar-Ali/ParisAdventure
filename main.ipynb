{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(page_source): # avoir la data sans les html tags et les \\n \\t etc ...\n",
    "    print(page_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_data(df, name):\n",
    "    df = df.append({\n",
    "        'name': name,\n",
    "    }, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui scrap les données\n",
    "def scrap(n):\n",
    "    df = pd.DataFrame(columns=['name', 'localisation', 'tjm', 'available', 'mission_count'])\n",
    "    for i in range(n):\n",
    "        driver = webdriver.Firefox() #ouvrir le navigateur\n",
    "        driver.get(\"https://www.malt.fr/all-freelances?p=\"+str(i+1)) #ouvrir la page\n",
    "\n",
    "        time.sleep(5) #attendre 5 secondes\n",
    "\n",
    "        page_source = driver.page_source #récupérer le code source de la page\n",
    "        # cleaned_data = clean_data(page_source) #nettoyer les données\n",
    "        df = pd.read_html(page_source)\n",
    "        \n",
    "        # append_data(df, clean_data) #ajouter les données à la liste\n",
    "        \n",
    "        driver.quit() #fermer le navigateur\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59004/1457766503.py:12: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(page_source)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No tables found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/lux/Documents/ScrapMalt/main.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/main.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Appel de la fonction\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/main.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m liste_page \u001b[39m=\u001b[39m scrap(\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32m/home/lux/Documents/ScrapMalt/main.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/main.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m page_source \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mpage_source \u001b[39m#récupérer le code source de la page\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/main.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# cleaned_data = clean_data(page_source) #nettoyer les données\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/main.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_html(page_source)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/main.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# append_data(df, clean_data) #ajouter les données à la liste\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lux/Documents/ScrapMalt/main.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m driver\u001b[39m.\u001b[39mquit() \u001b[39m#fermer le navigateur\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ScrapMalt/.venv/lib/python3.11/site-packages/pandas/io/html.py:1245\u001b[0m, in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[0m\n\u001b[1;32m   1229\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(io, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[1;32m   1230\u001b[0m     [\n\u001b[1;32m   1231\u001b[0m         is_file_like(io),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     ]\n\u001b[1;32m   1236\u001b[0m ):\n\u001b[1;32m   1237\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1238\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing literal html to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mread_html\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1239\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. To read from a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1242\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1243\u001b[0m     )\n\u001b[0;32m-> 1245\u001b[0m \u001b[39mreturn\u001b[39;00m _parse(\n\u001b[1;32m   1246\u001b[0m     flavor\u001b[39m=\u001b[39;49mflavor,\n\u001b[1;32m   1247\u001b[0m     io\u001b[39m=\u001b[39;49mio,\n\u001b[1;32m   1248\u001b[0m     match\u001b[39m=\u001b[39;49mmatch,\n\u001b[1;32m   1249\u001b[0m     header\u001b[39m=\u001b[39;49mheader,\n\u001b[1;32m   1250\u001b[0m     index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m   1251\u001b[0m     skiprows\u001b[39m=\u001b[39;49mskiprows,\n\u001b[1;32m   1252\u001b[0m     parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m   1253\u001b[0m     thousands\u001b[39m=\u001b[39;49mthousands,\n\u001b[1;32m   1254\u001b[0m     attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1255\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   1256\u001b[0m     decimal\u001b[39m=\u001b[39;49mdecimal,\n\u001b[1;32m   1257\u001b[0m     converters\u001b[39m=\u001b[39;49mconverters,\n\u001b[1;32m   1258\u001b[0m     na_values\u001b[39m=\u001b[39;49mna_values,\n\u001b[1;32m   1259\u001b[0m     keep_default_na\u001b[39m=\u001b[39;49mkeep_default_na,\n\u001b[1;32m   1260\u001b[0m     displayed_only\u001b[39m=\u001b[39;49mdisplayed_only,\n\u001b[1;32m   1261\u001b[0m     extract_links\u001b[39m=\u001b[39;49mextract_links,\n\u001b[1;32m   1262\u001b[0m     dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[1;32m   1263\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   1264\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/ScrapMalt/.venv/lib/python3.11/site-packages/pandas/io/html.py:1008\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1007\u001b[0m     \u001b[39massert\u001b[39;00m retained \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m  \u001b[39m# for mypy\u001b[39;00m\n\u001b[0;32m-> 1008\u001b[0m     \u001b[39mraise\u001b[39;00m retained\n\u001b[1;32m   1010\u001b[0m ret \u001b[39m=\u001b[39m []\n\u001b[1;32m   1011\u001b[0m \u001b[39mfor\u001b[39;00m table \u001b[39min\u001b[39;00m tables:\n",
      "File \u001b[0;32m~/Documents/ScrapMalt/.venv/lib/python3.11/site-packages/pandas/io/html.py:988\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    977\u001b[0m p \u001b[39m=\u001b[39m parser(\n\u001b[1;32m    978\u001b[0m     io,\n\u001b[1;32m    979\u001b[0m     compiled_match,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    984\u001b[0m     storage_options,\n\u001b[1;32m    985\u001b[0m )\n\u001b[1;32m    987\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 988\u001b[0m     tables \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mparse_tables()\n\u001b[1;32m    989\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m caught:\n\u001b[1;32m    990\u001b[0m     \u001b[39m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[1;32m    991\u001b[0m     \u001b[39m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[1;32m    992\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(io, \u001b[39m\"\u001b[39m\u001b[39mseekable\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m io\u001b[39m.\u001b[39mseekable():\n",
      "File \u001b[0;32m~/Documents/ScrapMalt/.venv/lib/python3.11/site-packages/pandas/io/html.py:248\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_tables\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    241\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[39m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m     tables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_tables(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_doc(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmatch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattrs)\n\u001b[1;32m    249\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[39mfor\u001b[39;00m table \u001b[39min\u001b[39;00m tables)\n",
      "File \u001b[0;32m~/Documents/ScrapMalt/.venv/lib/python3.11/site-packages/pandas/io/html.py:603\u001b[0m, in \u001b[0;36m_BeautifulSoupHtml5LibFrameParser._parse_tables\u001b[0;34m(self, document, match, attrs)\u001b[0m\n\u001b[1;32m    601\u001b[0m tables \u001b[39m=\u001b[39m document\u001b[39m.\u001b[39mfind_all(element_name, attrs\u001b[39m=\u001b[39mattrs)\n\u001b[1;32m    602\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tables:\n\u001b[0;32m--> 603\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo tables found\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    605\u001b[0m result \u001b[39m=\u001b[39m []\n\u001b[1;32m    606\u001b[0m unique_tables \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: No tables found"
     ]
    }
   ],
   "source": [
    "# Appel de la fonction\n",
    "liste_page = scrap(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
